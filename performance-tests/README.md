# Guide des Tests de Performance

## üéØ Objectifs des Tests

Ce guide d√©crit comment ex√©cuter une suite compl√®te de tests de performance pour comparer REST, SOAP, GraphQL et gRPC.

## üìã Pr√©paration

### 1. V√©rifier que tous les services sont op√©rationnels

```bash
# V√©rifier l'√©tat des services
docker-compose ps

# Services requis:
# - postgres (healthy)
# - backend-spring (running)
# - backend-graphql (running)
# - backend-grpc (running)
# - prometheus (running)
# - grafana (running)
# - jaeger (running)
```

### 2. Installer les outils de test

```bash
# k6
# Windows (via Chocolatey)
choco install k6

# ou t√©l√©charger depuis: https://k6.io/docs/getting-started/installation/

# Locust
pip install locust

# JMeter
# T√©l√©charger depuis: https://jmeter.apache.org/download_jmeter.cgi
# Extraire et ajouter bin/ au PATH

# Gatling
# D√©j√† inclus dans le projet via Maven
```

## üß™ Sc√©narios de Test

### Sc√©nario 1: Test de Charge Baseline (10 utilisateurs)

**Objectif**: √âtablir les performances de r√©f√©rence

#### REST
```bash
cd performance-tests/k6
k6 run --vus 10 --duration 2m rest-test.js
```

#### GraphQL
```bash
k6 run --vus 10 --duration 2m graphql-test.js
```

#### M√©triques attendues:
- Latence moyenne < 100ms
- Taux d'erreur < 1%
- RPS > 50

### Sc√©nario 2: Test de Charge Moyenne (100 utilisateurs)

**Objectif**: Simuler une charge typique

#### REST avec Locust
```bash
cd performance-tests/locust
locust -f rest-locustfile.py --host=http://localhost:8080 \
  --users 100 --spawn-rate 10 --run-time 5m --headless \
  --csv=results/rest-100users
```

#### GraphQL avec Locust
```bash
locust -f graphql-locustfile.py --host=http://localhost:4000 \
  --users 100 --spawn-rate 10 --run-time 5m --headless \
  --csv=results/graphql-100users
```

#### M√©triques attendues:
- Latence p95 < 500ms
- Taux d'erreur < 2%
- RPS > 200

### Sc√©nario 3: Test de Charge √âlev√©e (500 utilisateurs)

**Objectif**: Tester la scalabilit√©

```bash
# REST
k6 run --vus 500 --duration 5m rest-test.js

# GraphQL
k6 run --vus 500 --duration 5m graphql-test.js
```

#### M√©triques attendues:
- Latence p95 < 2000ms
- Taux d'erreur < 5%
- RPS > 500

### Sc√©nario 4: Test de Stress (1000 utilisateurs)

**Objectif**: Identifier les limites du syst√®me

```bash
# REST
locust -f rest-locustfile.py --host=http://localhost:8080 \
  --users 1000 --spawn-rate 50 --run-time 10m --headless

# GraphQL
locust -f graphql-locustfile.py --host=http://localhost:4000 \
  --users 1000 --spawn-rate 50 --run-time 10m --headless
```

### Sc√©nario 5: Test de Spike

**Objectif**: Tester la r√©silience face √† des pics soudains

```bash
# Configuration k6 avec stages
k6 run --stages '10s:10,30s:1000,10s:10,30s:100' rest-test.js
```

### Sc√©nario 6: Test d'Endurance

**Objectif**: V√©rifier la stabilit√© sur une longue p√©riode

```bash
# Test sur 1 heure avec 100 utilisateurs constants
k6 run --vus 100 --duration 1h rest-test.js
```

## üìä Tailles de Messages

### Configuration des Payloads

Les tests incluent 3 tailles de messages:

#### Petit (1 KB) - R√©servation Simple
```json
{
  "clientId": 1,
  "roomId": 1,
  "checkInDate": "2025-12-25",
  "checkOutDate": "2025-12-28",
  "numberOfGuests": 2
}
```

#### Moyen (10 KB) - Avec D√©tails
```json
{
  "clientId": 1,
  "roomId": 1,
  "checkInDate": "2025-12-25",
  "checkOutDate": "2025-12-28",
  "numberOfGuests": 2,
  "specialRequests": "Long text with special requirements...",
  "preferences": {
    "floor": "high",
    "view": "sea",
    "bedType": "king"
  },
  "additionalServices": [...]
}
```

#### Grand (100 KB) - Avec Historique
Inclut l'historique complet du client, pr√©f√©rences d√©taill√©es, et m√©tadonn√©es.

## üìà Collecte des M√©triques

### Prometheus Queries

```promql
# Latence moyenne
rate(http_server_requests_seconds_sum[5m]) / rate(http_server_requests_seconds_count[5m])

# Percentile 95
histogram_quantile(0.95, rate(http_server_requests_seconds_bucket[5m]))

# Taux de requ√™tes
rate(http_server_requests_seconds_count[1m])

# Taux d'erreur
rate(http_server_requests_seconds_count{status=~"5.."}[5m]) / rate(http_server_requests_seconds_count[5m])
```

### Jaeger Tracing

1. Ouvrir http://localhost:16686
2. S√©lectionner le service (hotel-reservation-spring, hotel-reservation-graphql)
3. Filtrer par op√©ration
4. Analyser les traces pour identifier les goulots d'√©tranglement

### Grafana Dashboards

1. Importer les dashboards recommand√©s:
   - Spring Boot: 6756
   - JVM: 4701
   - PostgreSQL: 9628

2. Cr√©er un dashboard personnalis√© pour comparer les APIs

## üìù Analyse des R√©sultats

### 1. Exporter les R√©sultats

#### k6
```bash
k6 run --out json=results.json rest-test.js
```

#### Locust
```bash
# R√©sultats disponibles dans results/*.csv
# - results_stats.csv: Statistiques globales
# - results_stats_history.csv: Historique temporel
# - results_failures.csv: √âchecs
```

### 2. G√©n√©rer des Rapports

#### k6 Report
```bash
# Installer k6-reporter
npm install -g k6-to-junit

# Convertir les r√©sultats
k6-to-junit results.json
```

#### JMeter HTML Report
```bash
jmeter -g results.jtl -o report/
```

### 3. Comparer les APIs

Cr√©er un tableau comparatif:

| M√©trique | REST | SOAP | GraphQL | gRPC |
|----------|------|------|---------|------|
| Latence moyenne | | | | |
| Latence p95 | | | | |
| RPS max | | | | |
| Taux d'erreur | | | | |
| CPU moyen | | | | |
| M√©moire moyenne | | | | |

## üîç Checklist de Test Complet

### Phase 1: Tests Fonctionnels
- [ ] REST: Toutes les op√©rations CRUD fonctionnent
- [ ] SOAP: Toutes les op√©rations SOAP fonctionnent
- [ ] GraphQL: Toutes les queries/mutations fonctionnent
- [ ] gRPC: Tous les RPCs fonctionnent

### Phase 2: Tests de Performance
- [ ] Test baseline (10 users) pour chaque API
- [ ] Test charge moyenne (100 users) pour chaque API
- [ ] Test charge √©lev√©e (500 users) pour chaque API
- [ ] Test de stress (1000 users) pour chaque API

### Phase 3: Tests de Scalabilit√©
- [ ] Test de mont√©e en charge progressive
- [ ] Test de spike
- [ ] Test d'endurance (1h+)

### Phase 4: Tests de R√©silience
- [ ] Test avec panne de base de donn√©es
- [ ] Test avec latence r√©seau simul√©e
- [ ] Test de r√©cup√©ration apr√®s erreur

### Phase 5: Collecte des M√©triques
- [ ] M√©triques Prometheus collect√©es
- [ ] Traces Jaeger analys√©es
- [ ] Dashboards Grafana cr√©√©s
- [ ] Logs agr√©g√©s dans Elasticsearch

### Phase 6: Analyse et Rapport
- [ ] Tableaux comparatifs cr√©√©s
- [ ] Graphiques de performance g√©n√©r√©s
- [ ] Recommandations document√©es
- [ ] Rapport final r√©dig√©

## üö® Troubleshooting

### Probl√®me: Taux d'erreur √©lev√©

**Solutions**:
1. V√©rifier les logs des services
2. Augmenter les ressources (CPU, m√©moire)
3. Optimiser les requ√™tes SQL
4. Augmenter le pool de connexions DB

### Probl√®me: Latence √©lev√©e

**Solutions**:
1. Activer le caching
2. Optimiser les index DB
3. R√©duire le nombre de requ√™tes SQL (N+1 problem)
4. Utiliser la pagination

### Probl√®me: Services crashent sous charge

**Solutions**:
1. Augmenter les limites de m√©moire JVM
2. Optimiser le garbage collection
3. Identifier les fuites m√©moire
4. Utiliser le pooling de connexions

## üìû Support

Pour toute question ou probl√®me:
1. Consulter les logs: `docker-compose logs [service]`
2. V√©rifier le dashboard Grafana
3. Examiner les traces dans Jaeger
4. Consulter la documentation des outils

## üìö Ressources

- [k6 Documentation](https://k6.io/docs/)
- [Locust Documentation](https://docs.locust.io/)
- [JMeter User Manual](https://jmeter.apache.org/usermanual/index.html)
- [Gatling Documentation](https://gatling.io/docs/)
- [Prometheus Query Examples](https://prometheus.io/docs/prometheus/latest/querying/examples/)
- [Grafana Tutorials](https://grafana.com/tutorials/)
